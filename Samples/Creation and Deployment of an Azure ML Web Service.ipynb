{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy of Azure ML web services\n",
    "\n",
    "Although web services can be created directly within [Azure ML Studio](https://studio.azureml.net), in some cases it may be more straightforward to develop and deploy a web service entirely within a Python notebook. Python notebooks allow rapid prototyping and allow developers to include commentary in Markdown. This tutorial demonstrates how the [`azureml`](https://github.com/Azure/Azure-MachineLearning-ClientLibrary-Python) package can be used to deploy Azure ML web services directly from within a Python notebook (or other Python environment).\n",
    "\n",
    "> **Note**: the `azureml` package presently works only with Python 2; be sure to set the notebook's kernel appropriately.\n",
    "\n",
    "[An R version](https://notebooks.azure.com/library/MMYTqvZg30o) of this tutorial is also available on [Azure Notebooks](https://notebooks.azure.com/).\n",
    "\n",
    "In this notebook:\n",
    "- [Prerequisites](#Prerequisites)\n",
    "   - [Credentials needed to connect to your workspace](#Credentials-needed-to-connect-to-your-workspace)\n",
    "- [Motivation: beaver fever](#Motivation:-beaver-fever)\n",
    "   - [Loading and exploring the dataset](#Loading-and-exploring-the-dataset)\n",
    "   - [Transferring data to and from Azure ML Studio](#Transferring-data-to-and-from-Azure-ML-Studio)\n",
    "- [Creating the predictive model](#Creating-the-predictive-model)\n",
    "- [Deploying the model as a web service](#Deploying-the-model-as-a-web-service)\n",
    "- [Consuming the web service](#Consuming-the-web-service)\n",
    "\n",
    "Refer to the [azureml GitHub repository](https://github.com/Azure/Azure-MachineLearning-ClientLibrary-Python) for more information on its capabilities.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Familiarity with Azure ML Studio\n",
    "- A workspace in Azure ML Studio\n",
    "- Familiarity with Python\n",
    "- A Python notebook with the `azureml` library installed ([Azure Notebooks](https://notebooks.azure.com/) includes `azureml` by default).\n",
    "\n",
    "### Credentials needed to connect to your workspace\n",
    "\n",
    "The `azureml` package uses your workspace ID and authorization token to connect to the workspace, provide that you're the owner of the workspace (authorized users who are not owners need to ask an owner for these details):\n",
    "\n",
    "1. Navigate to your workspace on [Azure ML Studio](https://studio.azureml.net) and select the **Settings** button on the left pane:\n",
    "\n",
    "    ![Settings button](https://github.com/Microsoft/AzureNotebooks/blob/master/Samples/images/azure-ml-studio-settings.png?raw=true)<br/><br/>\n",
    "\n",
    "1. Your workspace ID is on the **Name** tab of the **Settings** page: replace the value of `workspace_id` in the code cell below with this value.\n",
    "\n",
    "    ![Location of workspace ID](https://github.com/Microsoft/AzureNotebooks/blob/master/Samples/images/azure-ml-studio-workspace-id.png?raw=true)<br/><br/>\n",
    "\n",
    "1. Select the **Authorization Tokens** tab and copy either token into the `authorization_token` value in the code cell below.\n",
    "\n",
    "    ![Location of authorization token](https://github.com/Microsoft/AzureNotebooks/blob/master/Samples/images/azure-ml-studio-tokens.png?raw=true)<br/><br/>\n",
    "\n",
    "1. Run the code cell; if it runs without error, you're ready to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml import Workspace\n",
    "\n",
    "# Replace the values with those from your own Azure ML Studio instance\n",
    "workspace_id = 'your_workspace_id'\n",
    "authorization_token = 'your_auth_token'\n",
    "ws = Workspace(workspace_id, authorization_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation: beaver fever\n",
    "\n",
    "Reynolds (1994) collected data on the body temperatures of female beavers living in Wisconsin. We use this dataset to train a decision tree model which predicts a beaver's body temperature. Then we create a web service based on this model that can be used to predict body temperatures for other beavers.\n",
    "\n",
    "> P. S. Reynolds (1994). \"Time-series analyses of beaver body temperatures.\" Chapter 11 of Lange, N., Ryan, L., Billard, L., Brillinger, D., Conquest, L. and Greenhouse, J. eds (1994) *Case Studies in Biometry*. New York: John Wiley and Sons.\n",
    "\n",
    "## Loading and exploring the dataset\n",
    "\n",
    "Our dataset contains the following features:\n",
    "\n",
    "- `time`: The time of day on which the recording was made\n",
    "- `activ`: Binary indicator of whether activity is occurring outside of the beaver lodge\n",
    "- `beaver`: The beaver being measured\n",
    "- `temp`: The recorded body temperature\n",
    "\n",
    "Let's load the dataset and plot each of these features on the same axes to see whether any patterns may be present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydataset --disable-pip-version-check -q\n",
    "import pandas as pd\n",
    "from pydataset import data\n",
    "\n",
    "df = data('beav1')\n",
    "df['beaver'] = 1\n",
    "df = pd.concat([df, data('beav2')], sort=True)\n",
    "df.loc[df['beaver'].isnull(), 'beaver'] = 2\n",
    "df.drop('day', 1, inplace=True)\n",
    "\n",
    "%matplotlib inline\n",
    "from ggplot import *\n",
    "ggplot(aes(x='time', y='temp', color='beaver'), data=df) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the data reveals some conspicuous patterns. Beavers tend to be warmer when there is activity nearby, which tends to be in the afternoon and evening hours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(aes(x='time', y='temp', color='activ'), data=df) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also appears that all else being equal, Beaver 2 is warmer than Beaver 1.\n",
    "\n",
    "Notice that some trends seem to apply to a subset of the data. For example, if the measurement is from Beaver 2 *and* the beaver was active, then the body temperature is likely to be above 37.5; otherwise, the temperature is likely below 37.5. When trends apply to observation subsets that can be clearly defined using thresholding, decision tree models are good candidates. We therefore implement a decision tree model in the next section of the tutorial.\n",
    "\n",
    "### Transferring data to and from Azure ML Studio\n",
    "\n",
    "In this section we create a predictive model entirely in Azure Notebooks. (You can also use the `azureml` Python program to transfer the data over to Azure ML Studio to create your model there.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml import DataTypeIds\n",
    "\n",
    "dataset = ws.datasets.add_from_dataframe(\n",
    "              dataframe=df,\n",
    "              data_type_id=DataTypeIds.GenericCSV,\n",
    "              name='Beaver Body Temperature Data',\n",
    "              description='From Reynolds 1994 via pydataset'\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the code above, we can see the dataset listed in the **Datasets** section of the workspace (you may need to refresh the page):\n",
    "\n",
    "![Dataset shown in Azure ML Studio](https://github.com/Microsoft/AzureNotebooks/blob/master/Samples/images/azure-ml-studio-dataset.png?raw=true)<br/>\n",
    "\n",
    "It is also straightforward to list the datasets available in the workspace and transfer datasets from the workspace to the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join([i.name for i in ws.datasets if not i.is_example])) # only list user-created datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read some more of the metadata\n",
    "ds = ws.datasets['Beaver Body Temperature Data']\n",
    "print(ds.name)\n",
    "print(ds.description)\n",
    "print(ds.family_id)\n",
    "print(ds.data_type_id)\n",
    "print(ds.created_date)\n",
    "print(ds.size)\n",
    "\n",
    "# Read the contents\n",
    "df2 = ds.to_dataframe()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the predictive model\n",
    "\n",
    "To assess overfitting, we train our decision tree using only a subset of the available data. We can then assess performance using the withheld observation. Below, `sklearn`'s `train_test_split()` function is used to select 70% of the data points for training and 30% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[['activ', 'beaver', 'time']],\n",
    "        df['temp'],\n",
    "        test_size=0.3,\n",
    "        random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fit `scikit-learn`'s `DecisionTreeRegressor` model using the training data, then make predictions about the withheld body temperature measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_test_predictions = regressor.predict(X_test)\n",
    "print('R^2 for true vs. predicted test set temperature measurements: {:0.2f}'.format(r2_score(y_test, y_test_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like we have a reasonably accurate model!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the model as a web service\n",
    "\n",
    "To deploy our model as a predictive web service, we create a wrapper function that takes input data as an argument and calls `predict()` with our trained model and this input data, returning the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml import services\n",
    "\n",
    "@services.publish(workspace_id, authorization_token)\n",
    "@services.types(activ=int, beaver=float, time=int)\n",
    "@services.returns(float)\n",
    "\n",
    "# The name of your web service is set to this function's name\n",
    "def beaver_body_temp_predictor(activ, beaver, time):\n",
    "    return regressor.predict([activ, beaver, time])\n",
    "\n",
    "# Hold onto information about your web service so you can call it within the notebook later\n",
    "service_url = beaver_body_temp_predictor.service.url \n",
    "api_key = beaver_body_temp_predictor.service.api_key\n",
    "help_url = beaver_body_temp_predictor.service.help_url\n",
    "service_id = beaver_body_temp_predictor.service.service_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consuming the web service\n",
    "\n",
    "While you are in the notebook session in which the web service was created, you can call the predictor directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beaver_body_temp_predictor.service(0, 1, 1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At any later time, you can use the stored API key and service URL to call the service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import json\n",
    "\n",
    "data = {\"Inputs\": { \n",
    "            \"input1\": {\n",
    "                \"ColumnNames\": [ \"beaver\", \"activ\", \"time\"],\n",
    "                \"Values\": [[\"1\", \"0\", \"1200\"]] \n",
    "            }\n",
    "        }, # specified feature values\n",
    "        \n",
    "        \"GlobalParameters\": {}\n",
    "    }\n",
    "\n",
    "body = json.dumps(data)\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "req = urllib2.Request(service_url, body, headers) \n",
    "\n",
    "try:\n",
    "    response = urllib2.urlopen(req)\n",
    "    result = json.loads(response.read())  # load json-formatted string response as dictionary\n",
    "    print(result['Results']['output1']['value']['Values'][0][0]) # get the returned prediction\n",
    "    \n",
    "except urllib2.HTTPError, error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "    print(error.info())\n",
    "    print(json.loads(error.read()))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
